{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13262990",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab6a4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from test import evaluate_test_set\n",
    "import sts_data\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b85ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess import Preprocess\n",
    "import logging\n",
    "import torch\n",
    "import re\n",
    "from dataset import STSDataset\n",
    "from datasets import load_dataset,Dataset\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from spacy.lang.en import English\n",
    "from torchtext.legacy.data import Field\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1e7f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['sentence_A', 'sentence_B', 'relatedness_score'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset('text', data_files='SICK.txt')\n",
    "# dataset\n",
    "columns_mapping = {\n",
    "        \"sent1\": \"sentence_A\",\n",
    "        \"sent2\": \"sentence_B\",\n",
    "        \"label\": \"relatedness_score\",\n",
    "    }\n",
    "stopwords_path=\"stopwords-en.txt\"\n",
    "columns_mapping.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e44a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sick/default (download: 212.48 KiB, generated: 2.50 MiB, post-processed: Unknown size, total: 2.71 MiB) to /home/ibrahimssd/.cache/huggingface/datasets/sick/default/0.0.0/c6b3b0b44eb84b134851396d6d464e5cb8f026960519d640e087fe33472626db...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sick downloaded and prepared to /home/ibrahimssd/.cache/huggingface/datasets/sick/default/0.0.0/c6b3b0b44eb84b134851396d6d464e5cb8f026960519d640e087fe33472626db. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "sick_dataset = load_dataset('sick',download_mode='reuse_cache_if_exists')\n",
    "sick_dataset=sick_dataset.remove_columns(['label','id','entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset'])\n",
    "train_pd=pd.DataFrame.from_dict(sick_dataset['train'])\n",
    "validation_pd=pd.DataFrame.from_dict(sick_dataset['validation'])\n",
    "test_pd=pd.DataFrame.from_dict(sick_dataset['test'])\n",
    "sick_data=[train_pd,validation_pd,test_pd]\n",
    "# sick_df = pd.DataFrame(data=sick_dataset.data, columns=sick_dataset.column_names)\n",
    "# sen_A=columns_mapping['sent1']\n",
    "# sen_B= columns_mapping['sent2']\n",
    "# score=columns_mapping['label']\n",
    "# sick_df=sick_df[[sen_A,sen_B,score]]\n",
    "# pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be64544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sick_dataset['train']\n",
    "# Dataset.from_pandas(tran_pd)\n",
    "splits= list(sick_dataset.keys())\n",
    "type(sick_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de534416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "\"\"\"\n",
    "Performs basic text cleansing on the unstructured field \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, stpwds_file_path):\n",
    "        \"\"\"\n",
    "        Initializes regex patterns and loads stopwords\n",
    "        \"\"\"\n",
    "        # TODO implement\n",
    "        with open(stpwds_file_path) as fh:\n",
    "            self.stopwords=list(set(fh.read().split()))\n",
    "        self.noise_re = re.compile('\\\\b(%s)\\\\W'%('|'.join(map(re.escape,self.stopwords))),re.I)\n",
    "    \n",
    "\n",
    "    def perform_preprocessing(self, data, columns_mapping):\n",
    "        sen_A=columns_mapping['sent1']\n",
    "        sen_B= columns_mapping['sent2']\n",
    "        score=columns_mapping['label']\n",
    "        cleaned_data=[]\n",
    "        for data_frame in data:\n",
    "            groupA=list(data_frame[sen_A])\n",
    "            groupB=list(data_frame[sen_B])\n",
    "            ## normalize text to lower case\n",
    "            groupA=[x.lower() for x in groupA]\n",
    "            groupB=[x.lower() for x in groupB]\n",
    "            ## remove punctuations\n",
    "            groupA=[''.join(c for c in x if c not in string.punctuation) for x in groupA]\n",
    "            groupB=[''.join(c for c in x if c not in string.punctuation) for x in groupB]\n",
    "            ## remove stopwords\n",
    "            groupA=[self.noise_re.sub('',p) for p in groupA]\n",
    "            groupB=[self.noise_re.sub('',p) for p in groupB]\n",
    "            # Trim extra whitespace\n",
    "            groupA=[' '.join(x.split()) for x in groupA]\n",
    "            groupB=[' '.join(x.split()) for x in groupB]\n",
    "            # Remove numbers\n",
    "            groupA=[''.join(c for c in x if c not in '0123456789') for x in groupA]\n",
    "            groupB=[''.join(c for c in x if c not in '0123456789') for x in groupB]\n",
    "            ## return data_back to DataFrame\n",
    "            data_frame[sen_A]=groupA\n",
    "            data_frame[sen_B]=groupB\n",
    "            cleaned_data.append(data_frame)\n",
    "        \n",
    "        \n",
    "        sick_dataset={'train':Dataset.from_pandas(cleaned_data[0]),\n",
    "                      'validation':Dataset.from_pandas(cleaned_data[1]),\n",
    "                      'test':Dataset.from_pandas(cleaned_data[2])}\n",
    "        data_frame=pd.concat(cleaned_data, ignore_index=True)\n",
    "        \n",
    "        return sick_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fde4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "process=Preprocess(stopwords_path)\n",
    "formatted_data=process.perform_preprocessing(sick_data,columns_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.DataFrame(formatted_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f762528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4439\n"
     ]
    }
   ],
   "source": [
    "cols = list(columns_mapping.values())\n",
    "cols.pop()\n",
    "sen_list=list(train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1))\n",
    "sen_str = ' '.join(map(str, sen_list))\n",
    "print(len(sen_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177d693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(sen_str)\n",
    "\n",
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "# print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1172f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "counter = Counter(token_list)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "v= vocab(ordered_dict)\n",
    "\n",
    "PAD_token = 0   # Used for padding short sentences\n",
    "SOS_token = 1   # Start-of-sentence token\n",
    "EOS_token = 2   # End-of-sentence token\n",
    "special_words={PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "default_index = -1\n",
    "v.set_default_index(default_index)\n",
    "for key , value in special_words.items():\n",
    "    if value not in v: v.insert_token(value, key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7f19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stopwords_path) as fh:\n",
    "            stopwords=list(set(fh.read().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a252b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sentenceA&B']=train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534639c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtext.vocab:Loading vectors from .vector_cache/wiki.simple.vec.pt\n"
     ]
    }
   ],
   "source": [
    "text_field = Field(\n",
    "#     tokenize='basic_english', \n",
    "    lower=True,\n",
    "    include_lengths=True,\n",
    "    pad_token='PAD',\n",
    "    pad_first='SOS',\n",
    "    stop_words=stopwords,\n",
    ")\n",
    "\n",
    "# label_field = Field(sequential=False, use_vocab=False)\n",
    "preprocessed_text = train_data['sentenceA&B'].apply(lambda x: text_field.preprocess(x))\n",
    "text_field.build_vocab(\n",
    "    preprocessed_text, \n",
    "    vectors='fasttext.simple.300d')\n",
    "\n",
    "# get the vocab instance\n",
    "vocab = text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50a07ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [kids, playing, yard, standing, background, bo...\n",
       "1       [children, playing, house, standing, backgroun...\n",
       "2       [boys, playing, outdoors, smiling, nearby, kid...\n",
       "3       [kids, playing, outdoors, smile, kids, playing...\n",
       "4       [boys, playing, outdoors, smiling, nearby, kid...\n",
       "                              ...                        \n",
       "4434       [door, bald, band, playing, guitar, spotlight]\n",
       "4435                 [boiling, okra, pot, playing, drums]\n",
       "4436    [singing, heartily, playing, guitar, bicyclist...\n",
       "4437            [blue, yellow, ball, mitt, jumping, rope]\n",
       "4438    [dogs, resting, sidewalk, woman, knife, slicin...\n",
       "Name: sentenceA&B, Length: 4439, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634009d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data2tensors(self, data):\n",
    "#         \"\"\"\n",
    "#         Converts raw data sequences into vectorized sequences as tensors\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def get_data_loader(self, batch_size=8):\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def sort_batch(self, batch, targets, lengths):\n",
    "#         \"\"\"\n",
    "#         Sorts the data, lengths and target tensors based on the lengths\n",
    "#         of the sequences from longest to shortest in batch\n",
    "#         \"\"\"\n",
    "#         sents1_lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "#         sequence_tensor = batch[perm_idx]\n",
    "#         target_tensor = targets[perm_idx]\n",
    "#         return sequence_tensor.transpose(0, 1), target_tensor, sents1_lengths\n",
    "\n",
    "# def vectorize_sequence(self, sentence):\n",
    "#         \"\"\"\n",
    "#         Replaces tokens with their indices in vocabulary\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def pad_sequences(self, vectorized_sents, sents_lengths):\n",
    "#         \"\"\"\n",
    "#         Pads zeros at the end of each sequence in data tensor till max\n",
    "#         length of sequence in that batch\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "# def encode(vocab,string):\n",
    "#        return vocab[string]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2f9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['sentenceA&B'][0].apply(lambda x: print(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6da72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sentence):\n",
    "        \"\"\"\n",
    "        Replaces tokens with their indices in vocabulary\n",
    "        \"\"\"\n",
    "        splited_sentence=sentence.split()\n",
    "        encodes=[vocab[token] for token in splited_sentence]\n",
    "        return encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c60c0459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>sentenceA&amp;B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boys playing outdoors smiling nearby</td>\n",
       "      <td>boy playing outdoors smiling</td>\n",
       "      <td>3.6</td>\n",
       "      <td>[51, 4, 111, 133, 1390, 7, 4, 111, 133]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>person black jacket tricks motorbike</td>\n",
       "      <td>skilled person riding bicycle wheel</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[5, 11, 76, 427, 175, 0, 5, 18, 66, 332]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>children backbends gym</td>\n",
       "      <td>girls backbends playing outdoors</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[35, 885, 476, 118, 885, 4, 111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>player throwing ball</td>\n",
       "      <td>teams competing football match</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[85, 166, 21, 541, 606, 84, 1224]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>children standing wooden hut</td>\n",
       "      <td>children standing wooden hut</td>\n",
       "      <td>4.2</td>\n",
       "      <td>[35, 6, 172, 1071, 35, 6, 172, 1071]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>biker riding fence</td>\n",
       "      <td>dancing road</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[317, 18, 199, 25, 68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>woman playing electric guitar</td>\n",
       "      <td>kid playing guitar</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[2, 4, 402, 20, 79, 4, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>animal grazing grass</td>\n",
       "      <td>cop sitting police bike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[98, 522, 22, 910, 14, 969, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>dog snapping droplets water</td>\n",
       "      <td>girl band playing instrument</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3, 990, 735, 15, 8, 282, 4, 208]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>pushing motocross bike dirt hill</td>\n",
       "      <td>dog swimming tennis ball</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[240, 306, 29, 57, 80, 3, 74, 95, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence_A  \\\n",
       "0    boys playing outdoors smiling nearby   \n",
       "1    person black jacket tricks motorbike   \n",
       "2                  children backbends gym   \n",
       "3                    player throwing ball   \n",
       "4            children standing wooden hut   \n",
       "..                                    ...   \n",
       "490                    biker riding fence   \n",
       "491         woman playing electric guitar   \n",
       "492                  animal grazing grass   \n",
       "493           dog snapping droplets water   \n",
       "494      pushing motocross bike dirt hill   \n",
       "\n",
       "                              sentence_B  relatedness_score  \\\n",
       "0           boy playing outdoors smiling                3.6   \n",
       "1    skilled person riding bicycle wheel                3.4   \n",
       "2       girls backbends playing outdoors                3.8   \n",
       "3         teams competing football match                2.9   \n",
       "4           children standing wooden hut                4.2   \n",
       "..                                   ...                ...   \n",
       "490                         dancing road                1.2   \n",
       "491                   kid playing guitar                3.0   \n",
       "492              cop sitting police bike                1.0   \n",
       "493         girl band playing instrument                1.0   \n",
       "494             dog swimming tennis ball                1.0   \n",
       "\n",
       "                                  sentenceA&B  \n",
       "0     [51, 4, 111, 133, 1390, 7, 4, 111, 133]  \n",
       "1    [5, 11, 76, 427, 175, 0, 5, 18, 66, 332]  \n",
       "2            [35, 885, 476, 118, 885, 4, 111]  \n",
       "3           [85, 166, 21, 541, 606, 84, 1224]  \n",
       "4        [35, 6, 172, 1071, 35, 6, 172, 1071]  \n",
       "..                                        ...  \n",
       "490                    [317, 18, 199, 25, 68]  \n",
       "491                [2, 4, 402, 20, 79, 4, 20]  \n",
       "492           [98, 522, 22, 910, 14, 969, 29]  \n",
       "493         [3, 990, 735, 15, 8, 282, 4, 208]  \n",
       "494     [240, 306, 29, 57, 80, 3, 74, 95, 21]  \n",
       "\n",
       "[495 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(columns_mapping.values())\n",
    "cols.pop()\n",
    "train_data= pd.DataFrame(formatted_data['train'])\n",
    "val_data=pd.DataFrame(formatted_data['validation'])\n",
    "test_data=pd.DataFrame(formatted_data['test'])\n",
    "train_data['sentenceA&B']=train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "val_data['sentenceA&B']=val_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_data['sentenceA&B']=test_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "codes=[]\n",
    "for sentence in val_data['sentenceA&B']:\n",
    "    encodes= vectorize_sequence(sentence)\n",
    "    codes.append(encodes)\n",
    "val_data['sentenceA&B'] = codes\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fe4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2tensors(data):\n",
    "        \"\"\"\n",
    "        Converts raw data sequences into vectorized sequences as tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        data['sent1_tensor']=data['sent1_tensor'].apply(lambda lis : torch.as_tensor(lis))\n",
    "        data['sent2_tensor']=data['sent2_tensor'].apply(lambda lis : torch.as_tensor(lis))\n",
    "           \n",
    "        \n",
    "        \n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "334dd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data2tensors(formatted_data)['train'])[\"sentenceA&B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e617eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x:DataLoader(formatted_data[x],32, shuffle=True, num_workers=4) for x in ['train','validation','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3637178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eb20f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(dataloaders['train']))\n",
    "# from torch.utils import data\n",
    "# train_tensor = data.TensorDataset(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74915ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils import data\n",
    "# train_tensor = data.TensorDataset(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5702913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = {'train': torch.utils.data.DataLoader(STSDataset(sts_train_df, batch_size=64)),\n",
    "#                'val': torch.utils.data.DataLoader(STSDataset(sts_dev_df, batch_size=64))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b415d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_target = torch.tensor(train['Target'].values.astype(np.float32))\n",
    "# train = torch.tensor(train.drop('Target', axis = 1).values.astype(np.float32)) \n",
    "# train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "# train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0612f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df= pd.DataFrame(formatted_data['train'])\n",
    "val_data_df=pd.DataFrame(formatted_data['validation'])\n",
    "test_data_df=pd.DataFrame(formatted_data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a697f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['sent1_tensor']=train_data_df['sentence_A'].apply(lambda sen: vectorize_sequence(sen))\n",
    "train_data_df['sent2_tensor']=train_data_df['sentence_B'].apply(lambda sen: vectorize_sequence(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f33b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_df = torch.tensor(train_data_df['sentence_A'].values.astype(np.float32))\n",
    "train_data_df=data2tensors(train_data_df)\n",
    "train_data_df['sents1_length_tensor']=train_data_df['sent1_tensor'].apply(lambda tensor : torch.tensor(len(tensor)))\n",
    "train_data_df['sents2_length_tensor']=train_data_df['sent2_tensor'].apply(lambda tensor : torch.tensor(len(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da71456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f851e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# padded=pad_sequences(train_data_df['sent1_tensor'],padding=\"post\",truncating=”post”,maxlen=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d5b046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences):\n",
    "        \"\"\"\n",
    "        :param sequences: list of tensors\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = len(sequences)\n",
    "        max_len = max([s.shape[0] for s in sequences])\n",
    "        out_dims = (num, max_len, *sequences[0].shape[1:])\n",
    "        out_tensor = sequences[0].data.new(*out_dims).fill_(0)\n",
    "        mask = sequences[0].data.new(*out_dims).fill_(0)\n",
    "        for i, tensor in enumerate(sequences):\n",
    "            length = tensor.size(0)\n",
    "            out_tensor[i, :length] = tensor\n",
    "            mask[i, :length] = 1\n",
    "        return list(out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c09b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['sent1_tensor']=pad_sequences(train_data_df['sent1_tensor'])\n",
    "train_data_df['sent2_tensor']=pad_sequences(train_data_df['sent2_tensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff76a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['relatedness_score']=train_data_df['relatedness_score'].apply(lambda score : torch.tensor(score/sum(train_data_df['relatedness_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dd9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "763635b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard Pytorch Dataset class for loading datasets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class STSDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sent1_tensor,\n",
    "        sent2_tensor,\n",
    "        target_tensor,\n",
    "        sents1_length_tensor,\n",
    "        sents2_length_tensor,\n",
    "        raw_sents_1,\n",
    "        raw_sents_2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        initializes  and populates the the length, data and target tensors, and raw texts list\n",
    "        \"\"\"\n",
    "        \n",
    "        assert (\n",
    "            \n",
    "            \n",
    "            len(sent1_tensor)\n",
    "            == torch.tensor(list(target_tensor)).size(0)\n",
    "            == len(sent2_tensor)\n",
    "            == torch.tensor(list(sents1_length_tensor)).size(0)\n",
    "            == torch.tensor(list(sents2_length_tensor)).size(0)\n",
    "        )\n",
    "        self.sent1_tensor = sent1_tensor\n",
    "        self.sent2_tensor = sent2_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.sents1_length_tensor = sents1_length_tensor\n",
    "        self.sents2_length_tensor = sents2_length_tensor\n",
    "        self.raw_sents_1 = raw_sents_1\n",
    "        self.raw_sents_2 = raw_sents_2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        returns the tuple of data tensor, targets, lengths of sequences tensor and raw texts list\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.sent1_tensor[index],\n",
    "            self.sent2_tensor[index],\n",
    "            self.sents1_length_tensor[index],\n",
    "            self.sents2_length_tensor[index],\n",
    "            self.target_tensor[index],\n",
    "            self.raw_sents_1[index],\n",
    "            self.raw_sents_2[index],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the length of the data tensor.\n",
    "        \"\"\"\n",
    "        return torch.tensor(list(self.target_tensor)).size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddd72037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>sent1_tensor</th>\n",
       "      <th>sent2_tensor</th>\n",
       "      <th>sents1_length_tensor</th>\n",
       "      <th>sents2_length_tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kids playing yard standing background</td>\n",
       "      <td>boys yard playing standing background</td>\n",
       "      <td>tensor(0.0003)</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(144), tensor(6)...</td>\n",
       "      <td>[tensor(51), tensor(144), tensor(4), tensor(6)...</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>children playing house standing background</td>\n",
       "      <td>kids playing yard standing background</td>\n",
       "      <td>tensor(0.0002)</td>\n",
       "      <td>[tensor(35), tensor(4), tensor(403), tensor(6)...</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(144), tensor(6)...</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boys playing outdoors smiling nearby</td>\n",
       "      <td>kids playing outdoors smile</td>\n",
       "      <td>tensor(0.0003)</td>\n",
       "      <td>[tensor(51), tensor(4), tensor(111), tensor(13...</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(111), tensor(86...</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kids playing outdoors smile</td>\n",
       "      <td>kids playing yard standing background</td>\n",
       "      <td>tensor(0.0002)</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(111), tensor(86...</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(144), tensor(6)...</td>\n",
       "      <td>tensor(4)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boys playing outdoors smiling nearby</td>\n",
       "      <td>kids playing yard standing background</td>\n",
       "      <td>tensor(0.0002)</td>\n",
       "      <td>[tensor(51), tensor(4), tensor(111), tensor(13...</td>\n",
       "      <td>[tensor(65), tensor(4), tensor(144), tensor(6)...</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>door man</td>\n",
       "      <td>bald band playing guitar spotlight</td>\n",
       "      <td>tensor(7.0483e-05)</td>\n",
       "      <td>[tensor(349), tensor(0), tensor(0), tensor(0),...</td>\n",
       "      <td>[tensor(1480), tensor(282), tensor(4), tensor(...</td>\n",
       "      <td>tensor(2)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>boiling okra pot</td>\n",
       "      <td>playing drums</td>\n",
       "      <td>tensor(6.4075e-05)</td>\n",
       "      <td>[tensor(187), tensor(359), tensor(86), tensor(...</td>\n",
       "      <td>[tensor(4), tensor(339), tensor(0), tensor(0),...</td>\n",
       "      <td>tensor(3)</td>\n",
       "      <td>tensor(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>singing heartily playing guitar</td>\n",
       "      <td>bicyclist holding bike head people</td>\n",
       "      <td>tensor(6.4075e-05)</td>\n",
       "      <td>[tensor(47), tensor(1555), tensor(4), tensor(2...</td>\n",
       "      <td>[tensor(273), tensor(27), tensor(29), tensor(2...</td>\n",
       "      <td>tensor(4)</td>\n",
       "      <td>tensor(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>blue yellow ball mitt</td>\n",
       "      <td>jumping rope outside</td>\n",
       "      <td>tensor(7.6890e-05)</td>\n",
       "      <td>[tensor(24), tensor(39), tensor(21), tensor(13...</td>\n",
       "      <td>[tensor(16), tensor(60), tensor(0), tensor(0),...</td>\n",
       "      <td>tensor(4)</td>\n",
       "      <td>tensor(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>dogs resting sidewalk</td>\n",
       "      <td>woman knife slicing pepper</td>\n",
       "      <td>tensor(6.4075e-05)</td>\n",
       "      <td>[tensor(33), tensor(244), tensor(129), tensor(...</td>\n",
       "      <td>[tensor(2), tensor(157), tensor(28), tensor(45...</td>\n",
       "      <td>tensor(3)</td>\n",
       "      <td>tensor(4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4439 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence_A  \\\n",
       "0          kids playing yard standing background   \n",
       "1     children playing house standing background   \n",
       "2           boys playing outdoors smiling nearby   \n",
       "3                    kids playing outdoors smile   \n",
       "4           boys playing outdoors smiling nearby   \n",
       "...                                          ...   \n",
       "4434                                    door man   \n",
       "4435                            boiling okra pot   \n",
       "4436             singing heartily playing guitar   \n",
       "4437                       blue yellow ball mitt   \n",
       "4438                       dogs resting sidewalk   \n",
       "\n",
       "                                 sentence_B   relatedness_score  \\\n",
       "0     boys yard playing standing background      tensor(0.0003)   \n",
       "1     kids playing yard standing background      tensor(0.0002)   \n",
       "2               kids playing outdoors smile      tensor(0.0003)   \n",
       "3     kids playing yard standing background      tensor(0.0002)   \n",
       "4     kids playing yard standing background      tensor(0.0002)   \n",
       "...                                     ...                 ...   \n",
       "4434     bald band playing guitar spotlight  tensor(7.0483e-05)   \n",
       "4435                          playing drums  tensor(6.4075e-05)   \n",
       "4436     bicyclist holding bike head people  tensor(6.4075e-05)   \n",
       "4437                   jumping rope outside  tensor(7.6890e-05)   \n",
       "4438             woman knife slicing pepper  tensor(6.4075e-05)   \n",
       "\n",
       "                                           sent1_tensor  \\\n",
       "0     [tensor(65), tensor(4), tensor(144), tensor(6)...   \n",
       "1     [tensor(35), tensor(4), tensor(403), tensor(6)...   \n",
       "2     [tensor(51), tensor(4), tensor(111), tensor(13...   \n",
       "3     [tensor(65), tensor(4), tensor(111), tensor(86...   \n",
       "4     [tensor(51), tensor(4), tensor(111), tensor(13...   \n",
       "...                                                 ...   \n",
       "4434  [tensor(349), tensor(0), tensor(0), tensor(0),...   \n",
       "4435  [tensor(187), tensor(359), tensor(86), tensor(...   \n",
       "4436  [tensor(47), tensor(1555), tensor(4), tensor(2...   \n",
       "4437  [tensor(24), tensor(39), tensor(21), tensor(13...   \n",
       "4438  [tensor(33), tensor(244), tensor(129), tensor(...   \n",
       "\n",
       "                                           sent2_tensor sents1_length_tensor  \\\n",
       "0     [tensor(51), tensor(144), tensor(4), tensor(6)...            tensor(5)   \n",
       "1     [tensor(65), tensor(4), tensor(144), tensor(6)...            tensor(5)   \n",
       "2     [tensor(65), tensor(4), tensor(111), tensor(86...            tensor(5)   \n",
       "3     [tensor(65), tensor(4), tensor(144), tensor(6)...            tensor(4)   \n",
       "4     [tensor(65), tensor(4), tensor(144), tensor(6)...            tensor(5)   \n",
       "...                                                 ...                  ...   \n",
       "4434  [tensor(1480), tensor(282), tensor(4), tensor(...            tensor(2)   \n",
       "4435  [tensor(4), tensor(339), tensor(0), tensor(0),...            tensor(3)   \n",
       "4436  [tensor(273), tensor(27), tensor(29), tensor(2...            tensor(4)   \n",
       "4437  [tensor(16), tensor(60), tensor(0), tensor(0),...            tensor(4)   \n",
       "4438  [tensor(2), tensor(157), tensor(28), tensor(45...            tensor(3)   \n",
       "\n",
       "     sents2_length_tensor  \n",
       "0               tensor(5)  \n",
       "1               tensor(5)  \n",
       "2               tensor(4)  \n",
       "3               tensor(5)  \n",
       "4               tensor(5)  \n",
       "...                   ...  \n",
       "4434            tensor(5)  \n",
       "4435            tensor(2)  \n",
       "4436            tensor(5)  \n",
       "4437            tensor(3)  \n",
       "4438            tensor(4)  \n",
       "\n",
       "[4439 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "243b82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=  STSDataset(train_data_df['sent1_tensor'],\n",
    "                         train_data_df['sent2_tensor'],\n",
    "                         train_data_df['relatedness_score'],\n",
    "                         train_data_df['sents1_length_tensor'],\n",
    "                         train_data_df['sents2_length_tensor'],\n",
    "                         train_data_df['sentence_A'],\n",
    "                         train_data_df['sentence_B']\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2858ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_data_df['sent1_tensor'])\n",
    "# train_data_df['sents1_length_tensor'].size()\n",
    "# torch.tensor(list(target_tensor)).size(0)\n",
    "# train_data_df['sent1_tensor'][0]\n",
    "# train_data_df['relatedness_score'][0]\n",
    "# train_data_df['sents1_length_tensor'][0]\n",
    "# train_data_df['sentence_A'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c023118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e699fbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df['relatedness_score'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94cb6e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f4f355c67d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "448f4add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "len(dataiter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01def1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[227,   8,  25, 577, 562,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [ 48, 329, 192,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  3,  24, 514,   4,  21, 619,   0,   0,   0,   0,   0,   0,   0,   0]]), tensor([[  8,   9,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [ 48, 329, 192,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  3,  24, 514,   4,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), tensor([5, 4, 6]), tensor([3, 4, 6]), tensor([0.0002, 0.0002, 0.0003]), ('blond girl dancing sound equipment', 'putting suitcases trunk car', 'dog blue collar playing ball garden'), ('girl white dancing', 'putting suitcases trunk car', 'dog blue collar playing ball outside')]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce6d99c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[227,   8,  25, 577, 562,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 48, 329, 192,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  3,  24, 514,   4,  21, 619,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "642c240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d, m = 3, 5, 7\n",
    "embedding = torch.nn.Embedding(n, d, max_norm=True)\n",
    "W = torch.randn((m, d), requires_grad=True)\n",
    "idx = torch.tensor([1, 2])\n",
    "# a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
    "# b = embedding(idx) @ W.t()  # modifies weight in-place\n",
    "# out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
    "# loss = out.sigmoid().prod()\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47872b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0577,  0.0160,  0.9629,  0.1995, -0.1717],\n",
       "        [-0.0845,  0.0912, -0.4602,  0.7822, -0.4011]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b642cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= len(vocab)\n",
    "embedding_size= 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87b5e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(vocab_size, embedding_size, max_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7caadc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=torch.tensor([[121,  82,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "        [ 36,   4, 404,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74d74e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14, 300])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(sen).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fb1a9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2267,  0.0823, -0.0737,  ...,  0.2816,  0.0708, -0.1727],\n",
       "         [ 0.2845, -0.0039,  0.3620,  ..., -0.2849,  0.0120, -0.0268],\n",
       "         [ 0.2008, -0.0394,  0.3176,  ...,  0.0508, -0.2701, -0.2984],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1809, -0.3359, -0.2671,  ..., -0.1251,  0.1333, -0.3796],\n",
       "         [ 0.3038,  0.4029,  0.6689,  ..., -0.2629, -0.1546, -0.4536],\n",
       "         [ 0.0527, -0.0633, -0.4662,  ...,  0.3418, -0.0439, -0.1786],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors[sen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "181e478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights= vocab.vectors\n",
    "net = torch.nn.LSTM(10, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa9697a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils import similarity_score\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Wrapper class using Pytorch nn.Module to create the architecture for our model\n",
    "Architecture is based on the paper: \n",
    "A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING\n",
    "https://arxiv.org/pdf/1703.03130.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SiameseBiLSTMAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size,\n",
    "        output_size,\n",
    "        hidden_size,\n",
    "        vocab_size,\n",
    "        embedding_size,\n",
    "        embedding_weights,\n",
    "        lstm_layers,\n",
    "        device,\n",
    "        bidirectional,\n",
    "        self_attention_config,\n",
    "        fc_hidden_size,\n",
    "    ):\n",
    "        super(SiameseBiLSTMAttention, self).__init__()\n",
    "        \"\"\"\n",
    "        Initializes model layers and loads pre-trained embeddings from task 1\n",
    "        \"\"\"\n",
    "        ## model hyper parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.device = device\n",
    "        self.bidirectional = bidirectional\n",
    "        self.fc_hidden_size = fc_hidden_size\n",
    "        self.lstm_directions = (\n",
    "            2 if self.bidirectional else 1\n",
    "        )  ## decide directions based on input flag\n",
    "        \n",
    "        pass\n",
    "        ## model layers\n",
    "        # TODO initialize the look-up table.\n",
    "\n",
    "        # TODO assign the look-up table to the pre-trained fasttext word embeddings.\n",
    "        self.lookup=embedding_weights\n",
    "\n",
    "        ## TODO initialize lstm layer\n",
    "        self.bi_lstm = torch.nn.LSTM(self.embedding_size, self.lstm_hidden_size, \n",
    "                            lstm_layers, batch_first=True , bias= True,bidirectional=True)\n",
    "        ## TODO initialize self attention layers\n",
    "\n",
    "        ## incase we are using bi-directional lstm we'd have to take care of bi-directional outputs in\n",
    "        ## subsequent layers\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initializes hidden and context weight matrix before each\n",
    "                forward pass through LSTM\n",
    "        \"\"\"\n",
    "        h0 = torch.randn(self.lstm_directions*self.lstm_layers, batch_size, self.lstm_hidden_size)\n",
    "        c0 = torch.randn(self.lstm_directions*self.lstm_layers, batch_size, self.lstm_hidden_size)\n",
    "        \n",
    "        return h0, c0 \n",
    "\n",
    "    def forward_once(self, batch, lengths):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for each batch\n",
    "        \"\"\"\n",
    "\n",
    "        ## batch shape: (batch_size, seq_len)\n",
    "        batch_size , sequence_len = batch.size()z\n",
    "        ## embeddings shape: ( batch_size, seq_len, embedding_size)\n",
    "        \n",
    "#         h_init,c_init = self.init_hidden(batch_size)\n",
    "        input_batch_sequences= self.lookup[batch]\n",
    "        \n",
    "        output, (hn, cn) = self.bi_lstm(input_batch_sequences, (self.h_init, self.c_init))\n",
    "\n",
    "        return output , (hn , cn)\n",
    "\n",
    "    def forward(self, sent1_batch, sent2_batch, sent1_lengths, sent2_lengths):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for each batch\n",
    "        \"\"\"\n",
    "        ## TODO init context and hidden weights for lstm cell\n",
    "        self.h_init,self.c_init = self.init_hidden(self.batch_size)\n",
    "        output1,_ = self.forward_once(sent1_batch,sent1_lengths)\n",
    "        self.h_init,self.c_init = self.init_hidden(self.batch_size)\n",
    "        output2,_ = self.forward_once(sent2_batch,sent2_lengths)\n",
    "        \n",
    "        pass\n",
    "        # TODO implement forward pass on both sentences. calculate similarity using similarity_score()\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the attention block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        # TODO implement\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    ## the forward function would receive lstm's all hidden states as input\n",
    "    def forward(self, attention_input):\n",
    "        # TODO implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3a1824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "output_size = 1\n",
    "hidden_size = 128\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 300\n",
    "embedding_weights = vocab.vectors\n",
    "lstm_layers = 4\n",
    "learning_rate = 1e-1\n",
    "fc_hidden_size = 64\n",
    "max_epochs = 5\n",
    "bidirectional = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## self attention config\n",
    "self_attention_config = {\n",
    "    \"hidden_size\": 150,  ## refers to variable 'da' in the ICLR paper\n",
    "    \"output_size\": 20,  ## refers to variable 'r' in the ICLR paper\n",
    "    \"penalty\": 0.0,  ## refers to penalty coefficient term in the ICLR paper\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75eae4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseBiLSTMAttention(\n",
       "  (bi_lstm): LSTM(300, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## init siamese lstm\n",
    "siamese_lstm_attention = SiameseBiLSTMAttention(\n",
    "    batch_size=batch_size,\n",
    "    output_size=output_size,\n",
    "    hidden_size=hidden_size,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    embedding_weights=embedding_weights,\n",
    "    lstm_layers=lstm_layers,\n",
    "    self_attention_config=self_attention_config,\n",
    "    fc_hidden_size=fc_hidden_size,\n",
    "    device=device,\n",
    "    bidirectional=bidirectional,\n",
    ")\n",
    "## move model to device\n",
    "optimizer = torch.optim.SGD(siamese_lstm_attention.parameters(), learning_rate, momentum=0.9)\n",
    "siamese_lstm_attention.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9836dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_lstm_attention.forward(batch[0],batch[0],7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "788a48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.LSTM(10, 20, 2)\n",
    "inp = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(inp, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "971f0ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inp.size())\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fb31cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 300])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights[batch[0]].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c918d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.LSTM(embedding_size, hidden_size, lstm_layers, batch_first=True , bias= True,bidirectional=True)\n",
    "inp = embedding_weights[batch[0]]\n",
    "h0 = torch.randn(2*lstm_layers, 3, hidden_size)\n",
    "c0 = torch.randn(2*lstm_layers, 3, hidden_size)\n",
    "output, (hn, cn) = rnn(inp, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13bb6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 14, 300])\n",
      "torch.Size([3, 14, 256])\n",
      "torch.Size([8, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(inp.size())\n",
    "print(output.size())\n",
    "print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "111ddffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_emb_batch = (hn[-1, :, :] + hn[-2, :, :])\n",
    "# sum_lasthidden = output[:, -1, :hidden_size] + output[:, -1, hidden_size:]\n",
    "# states = output[:, :, :256] + output[:, :, 256]\n",
    "# hidden = hn.transpose(1,0).contiguous().view(3, -1)\n",
    "# u_emb_batch.size()\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8938cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\"\"\"\n",
    "Script for training the neural network and saving the better models \n",
    "while monitoring a metric like accuracy etc\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, dataloader, data, max_epochs, config_dict):\n",
    "    device = config_dict[\"device\"]\n",
    "    criterion = nn.MSELoss()\n",
    "    max_accuracy = 5e-1\n",
    "    train_loader , val_loader , test_loader = dataloader\n",
    "    train_generator = iter(train_loader)\n",
    "    \n",
    "    dictionary_info={}\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        \n",
    "        try:\n",
    "            # Samples the batch\n",
    "            sent1_batch, sent2_batch, sent1_lengths, sent2_lengths,targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "        except StopIteration:\n",
    "            # restart the generator if the previous generator is exhausted.\n",
    "            generator = iter(trainloader)\n",
    "            sent1_batch, sent2_batch, sent1_lengths, sent2_lengths, targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "        \n",
    "        \n",
    "        predictions= model.forward(sent1_batch, sent2_batch, sent1_lengths, sent2_lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predictions,targets) + attention_penalty_loss(annotation_weight_matrix, \n",
    "                                                                  penalty_coef, device)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TODO: computing accuracy using sklearn's function\n",
    "        ## acc = \n",
    "        #accuracy = (torch.argmax(predictions, axis=-1) == targets).float().mean()\n",
    "        acc=accuracy_score(y_true, y_pred)\n",
    "\n",
    "        ## compute model metrics on dev set\n",
    "        val_acc, val_loss = evaluate_dev_set(\n",
    "            model, data, criterion, dataloader, config_dict, device\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        if val_acc > max_accuracy:\n",
    "            max_accuracy = val_acc\n",
    "            logging.info(\n",
    "                \"new model saved\")  \n",
    "            \n",
    "            ## save the model if it is better than the prior best\n",
    "            torch.save(model.state_dict(), \"{}.pth\".format(config_dict[\"model_name\"]))\n",
    "\n",
    "        logging.info(\n",
    "            \"Train loss: {} - acc: {} -- Validation loss: {} - acc: {}\".format(\n",
    "                torch.mean(total_loss.data.float()), acc, val_loss, val_acc\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "        print('[%d/%d] loss: %.3f, accuracy: %.3f' %\n",
    "                   (i , max_epochs - 1, loss.item(), acc.item()))\n",
    "        if epoch == max_epochs - 1:\n",
    "               print('Final accuracy: %.3f, expected %.3f' %\n",
    "                         (accuracy.item(), 1.0))\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_dev_set(model, data, criterion, data_loader, config_dict, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model performance on dev data\n",
    "    \"\"\"\n",
    "    logging.info(\"Evaluating accuracy on dev set\")\n",
    "\n",
    "    # TODO implement\n",
    "    pass\n",
    "\n",
    "def attention_penalty_loss(annotation_weight_matrix, penalty_coef, device):\n",
    "    \"\"\"\n",
    "    This function computes the loss from annotation/attention matrix\n",
    "    to reduce redundancy in annotation matrix and for attention\n",
    "    to focus on different parts of the sequence corresponding to the\n",
    "    penalty term 'P' in the ICLR paper\n",
    "    ----------------------------------\n",
    "    'annotation_weight_matrix' refers to matrix 'A' in the ICLR paper\n",
    "    annotation_weight_matrix shape: (batch_size, attention_out, seq_len)\n",
    "    \"\"\"\n",
    "    batch_size, attention_out_size = annotation_weight_matrix.size(0), annotation_weight_matrix.size(1)\n",
    "    annotation_weight_matrix_trans = torch.transpose(annotation_weight_matrix, 0, 1)\n",
    "    identity = torch.eye(annotation_weight_matrix.size(0))\n",
    "    annotation_mul_difference=annotation_weight_matrix@annotation_weight_matrix_trans - identity\n",
    "    penalty = frobenius_norm(annotation_mul_difference)\n",
    "    return penalty_coef*penalty\n",
    "\n",
    "\n",
    "def frobenius_norm(annotation_mul_difference):\n",
    "    \"\"\"\n",
    "    Computes the frobenius norm of the annotation_mul_difference input as matrix\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    Args:\n",
    "      annotation_mul_difference= ||AAT - I||\n",
    " \n",
    "    Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "    \n",
    "#    torch.norm(annotation_mul_difference.float(), p='fro')\n",
    "#     torch.sum(torch.sum(torch.sum(annotation_mul_difference**2,1),1)**0.5).type(torch.DoubleTensor)\n",
    "    return torch.sqrt(torch.sum(annotation_mul_difference**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "257b1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "train_generator = iter(train_loader)\n",
    "for i in range(10):\n",
    "    try:\n",
    "        # Samples the batch\n",
    "        sent1_batch, sent2_batch, sent1_lengths, sent2_lengths, targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "    except StopIteration:\n",
    "        # restart the generator if the previous generator is exhausted.\n",
    "        generator = iter(trainloader)\n",
    "        sent1_batch, sent2_batch, sent1_lengths, sent2_lengths, targets,raw_sent1,raw_sent2= next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "343b88dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e94eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
