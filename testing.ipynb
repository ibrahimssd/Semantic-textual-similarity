{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13262990",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6a4f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 18:08:48.653045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-25 18:08:48.653072: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from test import evaluate_test_set\n",
    "import sts_data\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b85ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess import Preprocess\n",
    "import logging\n",
    "import torch\n",
    "import re\n",
    "from dataset import STSDataset\n",
    "from datasets import load_dataset,Dataset\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from spacy.lang.en import English\n",
    "from torchtext.legacy.data import Field\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1e7f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['sentence_A', 'sentence_B', 'relatedness_score'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset('text', data_files='SICK.txt')\n",
    "# dataset\n",
    "columns_mapping = {\n",
    "        \"sent1\": \"sentence_A\",\n",
    "        \"sent2\": \"sentence_B\",\n",
    "        \"label\": \"relatedness_score\",\n",
    "    }\n",
    "stopwords_path=\"stopwords-en.txt\"\n",
    "columns_mapping.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e44a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sick/default (download: 212.48 KiB, generated: 2.50 MiB, post-processed: Unknown size, total: 2.71 MiB) to /home/ibrahimssd/.cache/huggingface/datasets/sick/default/0.0.0/c6b3b0b44eb84b134851396d6d464e5cb8f026960519d640e087fe33472626db...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sick downloaded and prepared to /home/ibrahimssd/.cache/huggingface/datasets/sick/default/0.0.0/c6b3b0b44eb84b134851396d6d464e5cb8f026960519d640e087fe33472626db. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "sick_dataset = load_dataset('sick',download_mode='reuse_cache_if_exists')\n",
    "sick_dataset=sick_dataset.remove_columns(['label','id','entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset'])\n",
    "train_pd=pd.DataFrame.from_dict(sick_dataset['train'])\n",
    "validation_pd=pd.DataFrame.from_dict(sick_dataset['validation'])\n",
    "test_pd=pd.DataFrame.from_dict(sick_dataset['test'])\n",
    "sick_data=[train_pd,validation_pd,test_pd]\n",
    "# sick_df = pd.DataFrame(data=sick_dataset.data, columns=sick_dataset.column_names)\n",
    "# sen_A=columns_mapping['sent1']\n",
    "# sen_B= columns_mapping['sent2']\n",
    "# score=columns_mapping['label']\n",
    "# sick_df=sick_df[[sen_A,sen_B,score]]\n",
    "# pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be64544e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9532/2781948741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msick_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msick_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;36m4439\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# sick_dataset['train']\n",
    "# Dataset.from_pandas(tran_pd)\n",
    "splits= list(sick_dataset.keys())\n",
    "type(sick_dataset)\n",
    "len(train_data_df)\n",
    "4439/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de534416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "\"\"\"\n",
    "Performs basic text cleansing on the unstructured field \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, stpwds_file_path):\n",
    "        \"\"\"\n",
    "        Initializes regex patterns and loads stopwords\n",
    "        \"\"\"\n",
    "        # TODO implement\n",
    "        with open(stpwds_file_path) as fh:\n",
    "            self.stopwords=list(set(fh.read().split()))\n",
    "        self.noise_re = re.compile('\\\\b(%s)\\\\W'%('|'.join(map(re.escape,self.stopwords))),re.I)\n",
    "    \n",
    "\n",
    "    def perform_preprocessing(self, data, columns_mapping):\n",
    "        sen_A=columns_mapping['sent1']\n",
    "        sen_B= columns_mapping['sent2']\n",
    "        score=columns_mapping['label']\n",
    "        cleaned_data=[]\n",
    "        for data_frame in data:\n",
    "            groupA=list(data_frame[sen_A])\n",
    "            groupB=list(data_frame[sen_B])\n",
    "            ## normalize text to lower case\n",
    "            groupA=[x.lower() for x in groupA]\n",
    "            groupB=[x.lower() for x in groupB]\n",
    "            ## remove punctuations\n",
    "            groupA=[''.join(c for c in x if c not in string.punctuation) for x in groupA]\n",
    "            groupB=[''.join(c for c in x if c not in string.punctuation) for x in groupB]\n",
    "            ## remove stopwords\n",
    "            groupA=[self.noise_re.sub('',p) for p in groupA]\n",
    "            groupB=[self.noise_re.sub('',p) for p in groupB]\n",
    "            # Trim extra whitespace\n",
    "            groupA=[' '.join(x.split()) for x in groupA]\n",
    "            groupB=[' '.join(x.split()) for x in groupB]\n",
    "            # Remove numbers\n",
    "            groupA=[''.join(c for c in x if c not in '0123456789') for x in groupA]\n",
    "            groupB=[''.join(c for c in x if c not in '0123456789') for x in groupB]\n",
    "            ## return data_back to DataFrame\n",
    "            data_frame[sen_A]=groupA\n",
    "            data_frame[sen_B]=groupB\n",
    "            cleaned_data.append(data_frame)\n",
    "        \n",
    "        \n",
    "        sick_dataset={'train':Dataset.from_pandas(cleaned_data[0]),\n",
    "                      'validation':Dataset.from_pandas(cleaned_data[1]),\n",
    "                      'test':Dataset.from_pandas(cleaned_data[2])}\n",
    "        data_frame=pd.concat(cleaned_data, ignore_index=True)\n",
    "        \n",
    "        return sick_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "process=Preprocess(stopwords_path)\n",
    "formatted_data=process.perform_preprocessing(sick_data,columns_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.DataFrame(formatted_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f762528",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(columns_mapping.values())\n",
    "cols.pop()\n",
    "sen_list=list(train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1))\n",
    "sen_str = ' '.join(map(str, sen_list))\n",
    "print(len(sen_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(sen_str)\n",
    "\n",
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "# print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "counter = Counter(token_list)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "v= vocab(ordered_dict)\n",
    "\n",
    "PAD_token = 0   # Used for padding short sentences\n",
    "SOS_token = 1   # Start-of-sentence token\n",
    "EOS_token = 2   # End-of-sentence token\n",
    "special_words={PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "default_index = -1\n",
    "v.set_default_index(default_index)\n",
    "for key , value in special_words.items():\n",
    "    if value not in v: v.insert_token(value, key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stopwords_path) as fh:\n",
    "            stopwords=list(set(fh.read().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a252b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sentenceA&B']=train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534639c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = Field(\n",
    "#     tokenize='basic_english', \n",
    "    lower=True,\n",
    "    include_lengths=True,\n",
    "    pad_token='PAD',\n",
    "    pad_first='SOS',\n",
    "    stop_words=stopwords,\n",
    ")\n",
    "\n",
    "# label_field = Field(sequential=False, use_vocab=False)\n",
    "preprocessed_text = train_data['sentenceA&B'].apply(lambda x: text_field.preprocess(x))\n",
    "text_field.build_vocab(\n",
    "    preprocessed_text, \n",
    "    vectors='fasttext.simple.300d')\n",
    "\n",
    "# get the vocab instance\n",
    "vocab = text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text\n",
    "len(vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634009d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data2tensors(self, data):\n",
    "#         \"\"\"\n",
    "#         Converts raw data sequences into vectorized sequences as tensors\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def get_data_loader(self, batch_size=8):\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def sort_batch(self, batch, targets, lengths):\n",
    "#         \"\"\"\n",
    "#         Sorts the data, lengths and target tensors based on the lengths\n",
    "#         of the sequences from longest to shortest in batch\n",
    "#         \"\"\"\n",
    "#         sents1_lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "#         sequence_tensor = batch[perm_idx]\n",
    "#         target_tensor = targets[perm_idx]\n",
    "#         return sequence_tensor.transpose(0, 1), target_tensor, sents1_lengths\n",
    "\n",
    "# def vectorize_sequence(self, sentence):\n",
    "#         \"\"\"\n",
    "#         Replaces tokens with their indices in vocabulary\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "\n",
    "# def pad_sequences(self, vectorized_sents, sents_lengths):\n",
    "#         \"\"\"\n",
    "#         Pads zeros at the end of each sequence in data tensor till max\n",
    "#         length of sequence in that batch\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # TODO implement\n",
    "# def encode(vocab,string):\n",
    "#        return vocab[string]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['sentenceA&B'][0].apply(lambda x: print(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sentence):\n",
    "        \"\"\"\n",
    "        Replaces tokens with their indices in vocabulary\n",
    "        \"\"\"\n",
    "        splited_sentence=sentence.split()\n",
    "        encodes=[vocab[token] for token in splited_sentence]\n",
    "        return encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(columns_mapping.values())\n",
    "cols.pop()\n",
    "train_data= pd.DataFrame(formatted_data['train'])\n",
    "val_data=pd.DataFrame(formatted_data['validation'])\n",
    "test_data=pd.DataFrame(formatted_data['test'])\n",
    "train_data['sentenceA&B']=train_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "val_data['sentenceA&B']=val_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_data['sentenceA&B']=test_data[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "codes=[]\n",
    "for sentence in val_data['sentenceA&B']:\n",
    "    encodes= vectorize_sequence(sentence)\n",
    "    codes.append(encodes)\n",
    "val_data['sentenceA&B'] = codes\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2tensors(data):\n",
    "        \"\"\"\n",
    "        Converts raw data sequences into vectorized sequences as tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        data['sent1_tensor']=data['sent1_tensor'].apply(lambda lis : torch.as_tensor(lis))\n",
    "        data['sent2_tensor']=data['sent2_tensor'].apply(lambda lis : torch.as_tensor(lis))\n",
    "           \n",
    "        \n",
    "        \n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data2tensors(formatted_data)['train'])[\"sentenceA&B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e617eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x:DataLoader(formatted_data[x],32, shuffle=True, num_workers=4) for x in ['train','validation','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3637178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb20f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(dataloaders['train']))\n",
    "# from torch.utils import data\n",
    "# train_tensor = data.TensorDataset(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74915ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils import data\n",
    "# train_tensor = data.TensorDataset(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = {'train': torch.utils.data.DataLoader(STSDataset(sts_train_df, batch_size=64)),\n",
    "#                'val': torch.utils.data.DataLoader(STSDataset(sts_dev_df, batch_size=64))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_target = torch.tensor(train['Target'].values.astype(np.float32))\n",
    "# train = torch.tensor(train.drop('Target', axis = 1).values.astype(np.float32)) \n",
    "# train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "# train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df= pd.DataFrame(formatted_data['train'])\n",
    "val_data_df=pd.DataFrame(formatted_data['validation'])\n",
    "test_data_df=pd.DataFrame(formatted_data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a697f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['sent1_tensor']=train_data_df['sentence_A'].apply(lambda sen: vectorize_sequence(sen))\n",
    "train_data_df['sent2_tensor']=train_data_df['sentence_B'].apply(lambda sen: vectorize_sequence(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_df = torch.tensor(train_data_df['sentence_A'].values.astype(np.float32))\n",
    "train_data_df=data2tensors(train_data_df)\n",
    "train_data_df['sents1_length_tensor']=train_data_df['sent1_tensor'].apply(lambda tensor : torch.tensor(len(tensor)))\n",
    "train_data_df['sents2_length_tensor']=train_data_df['sent2_tensor'].apply(lambda tensor : torch.tensor(len(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da71456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# padded=pad_sequences(train_data_df['sent1_tensor'],padding=\"post\",truncating=”post”,maxlen=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences):\n",
    "        \"\"\"\n",
    "        :param sequences: list of tensors\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = len(sequences)\n",
    "        max_len = max([s.shape[0] for s in sequences])\n",
    "        out_dims = (num, max_len, *sequences[0].shape[1:])\n",
    "        out_tensor = sequences[0].data.new(*out_dims).fill_(0)\n",
    "        mask = sequences[0].data.new(*out_dims).fill_(0)\n",
    "        for i, tensor in enumerate(sequences):\n",
    "            length = tensor.size(0)\n",
    "            out_tensor[i, :length] = tensor\n",
    "            mask[i, :length] = 1\n",
    "        return list(out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['sent1_tensor']=pad_sequences(train_data_df['sent1_tensor'])\n",
    "train_data_df['sent2_tensor']=pad_sequences(train_data_df['sent2_tensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['relatedness_score']=train_data_df['relatedness_score'].apply(lambda score : torch.tensor(score/sum(train_data_df['relatedness_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dd9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763635b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard Pytorch Dataset class for loading datasets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class STSDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sent1_tensor,\n",
    "        sent2_tensor,\n",
    "        target_tensor,\n",
    "        sents1_length_tensor,\n",
    "        sents2_length_tensor,\n",
    "        raw_sents_1,\n",
    "        raw_sents_2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        initializes  and populates the the length, data and target tensors, and raw texts list\n",
    "        \"\"\"\n",
    "        \n",
    "        assert (\n",
    "            \n",
    "            \n",
    "            len(sent1_tensor)\n",
    "            == torch.tensor(list(target_tensor)).size(0)\n",
    "            == len(sent2_tensor)\n",
    "            == torch.tensor(list(sents1_length_tensor)).size(0)\n",
    "            == torch.tensor(list(sents2_length_tensor)).size(0)\n",
    "        )\n",
    "        self.sent1_tensor = sent1_tensor\n",
    "        self.sent2_tensor = sent2_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.sents1_length_tensor = sents1_length_tensor\n",
    "        self.sents2_length_tensor = sents2_length_tensor\n",
    "        self.raw_sents_1 = raw_sents_1\n",
    "        self.raw_sents_2 = raw_sents_2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        returns the tuple of data tensor, targets, lengths of sequences tensor and raw texts list\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.sent1_tensor[index],\n",
    "            self.sent2_tensor[index],\n",
    "            self.sents1_length_tensor[index],\n",
    "            self.sents2_length_tensor[index],\n",
    "            self.target_tensor[index],\n",
    "            self.raw_sents_1[index],\n",
    "            self.raw_sents_2[index],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the length of the data tensor.\n",
    "        \"\"\"\n",
    "        return torch.tensor(list(self.target_tensor)).size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd72037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=  STSDataset(train_data_df['sent1_tensor'],\n",
    "                         train_data_df['sent2_tensor'],\n",
    "                         train_data_df['relatedness_score'],\n",
    "                         train_data_df['sents1_length_tensor'],\n",
    "                         train_data_df['sents2_length_tensor'],\n",
    "                         train_data_df['sentence_A'],\n",
    "                         train_data_df['sentence_B']\n",
    "                         )\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_data_df['sent1_tensor'])\n",
    "# train_data_df['sents1_length_tensor'].size()\n",
    "# torch.tensor(list(target_tensor)).size(0)\n",
    "# train_data_df['sent1_tensor'][0]\n",
    "# train_data_df['relatedness_score'][0]\n",
    "# train_data_df['sents1_length_tensor'][0]\n",
    "# train_data_df['sentence_A'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023118a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['relatedness_score'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "len(dataiter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01def1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d, m = 3, 5, 7\n",
    "embedding = torch.nn.Embedding(n, d, max_norm=True)\n",
    "W = torch.randn((m, d), requires_grad=True)\n",
    "idx = torch.tensor([1, 2])\n",
    "# a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
    "# b = embedding(idx) @ W.t()  # modifies weight in-place\n",
    "# out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
    "# loss = out.sigmoid().prod()\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47872b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b642cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= len(vocab)\n",
    "embedding_size= 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(vocab_size, embedding_size, max_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caadc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=torch.tensor([[121,  82,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "        [ 36,   4, 404,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d74e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding(sen).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.vectors[sen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights= vocab.vectors\n",
    "net = torch.nn.LSTM(10, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef22ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(input1, input2):\n",
    "    # Get similarity predictions:\n",
    "    dif = input1.squeeze() - input2.squeeze()\n",
    "\n",
    "    norm = torch.norm(dif, p=1, dim=dif.dim() - 1)\n",
    "    y_hat = torch.exp(-norm)\n",
    "    y_hat = torch.clamp(y_hat, min=1e-7, max=1.0 - 1e-7)\n",
    "    return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b65dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sts_data import STSData\n",
    "\n",
    "columns_mapping = {\n",
    "        \"sent1\": \"sentence_A\",\n",
    "        \"sent2\": \"sentence_B\",\n",
    "        \"label\": \"relatedness_score\",\n",
    "    }\n",
    "dataset_name = \"sick\"\n",
    "sick_data = STSData(\n",
    "    dataset_name=dataset_name,\n",
    "    columns_mapping=columns_mapping,\n",
    "    normalize_labels=True,\n",
    "    normalization_const=5.0,\n",
    ")\n",
    "batch_size = 64\n",
    "sick_dataloaders = sick_data.get_data_loader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2448c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils import similarity_score\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Wrapper class using Pytorch nn.Module to create the architecture for our model\n",
    "Architecture is based on the paper: \n",
    "A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING\n",
    "https://arxiv.org/pdf/1703.03130.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SiameseBiLSTMAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size,\n",
    "        output_size,\n",
    "        hidden_size,\n",
    "        vocab_size,\n",
    "        embedding_size,\n",
    "        embedding_weights,\n",
    "        lstm_layers,\n",
    "        device,\n",
    "        bidirectional,\n",
    "        self_attention_config,\n",
    "        fc_hidden_size,\n",
    "    ):\n",
    "        super(SiameseBiLSTMAttention, self).__init__()\n",
    "        \"\"\"\n",
    "        Initializes model layers and loads pre-trained embeddings from task 1\n",
    "        \"\"\"\n",
    "        ## model hyper parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.device = device\n",
    "        self.bidirectional = bidirectional\n",
    "        self.fc_hidden_size = fc_hidden_size\n",
    "        self.lstm_directions = (\n",
    "            2 if self.bidirectional else 1\n",
    "        )  ## decide directions based on input flag\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## model layers\n",
    "        # TODO initialize the look-up table.\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        # TODO assign the look-up table to the pre-trained fasttext word embeddings.\n",
    "        \n",
    "        self.lookup= embedding_weights   #self.embeddings\n",
    "        \n",
    "        ## TODO initialize lstm layer\n",
    "        self.bi_lstm = torch.nn.LSTM(self.embedding_size, self.lstm_hidden_size, \n",
    "                            lstm_layers, batch_first=True , bias= True,bidirectional=True)\n",
    "        \n",
    "        ## TODO initialize self attention layers\n",
    "        self.SelfAtt= SelfAttention(2*self.lstm_hidden_size, self_attention_config['hidden_size'],\n",
    "                                    self_attention_config['output_size'])\n",
    "        \n",
    "        #Initialize fully connected layer\n",
    "        self.fc = nn.Linear(2*self.lstm_hidden_size * self_attention_config['output_size'], self.fc_hidden_size )\n",
    "        self.tanh = nn.Tanh()\n",
    "        ## incase we are using bi-directional lstm we'd have to take care of bi-directional outputs in\n",
    "        ## subsequent layers\n",
    "        \n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initializes hidden and context weight matrix before each\n",
    "                forward pass through LSTM\n",
    "        \"\"\"\n",
    "        h0 = torch.randn(self.lstm_directions*self.lstm_layers, batch_size, self.lstm_hidden_size)\n",
    "        c0 = torch.randn(self.lstm_directions*self.lstm_layers, batch_size, self.lstm_hidden_size)\n",
    "        \n",
    "        return h0, c0 \n",
    "\n",
    "    def forward_once(self, batch, lengths):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for each batch\n",
    "        \"\"\"\n",
    "\n",
    "        ## batch shape: (batch_size, seq_len)\n",
    "        batch_size , sequence_len = batch.size()\n",
    "        ## embeddings shape: ( batch_size, seq_len, embedding_size)\n",
    "        \n",
    "        #h_init,c_init = self.init_hidden(batch_size)\n",
    "        input_batch_sequences= self.lookup[batch]\n",
    "        \n",
    "        output, (hn, cn) = self.bi_lstm(input_batch_sequences, (self.h_init, self.c_init))\n",
    "\n",
    "        return output , (hn , cn)\n",
    "\n",
    "    def forward(self, sent1_batch, sent2_batch, sent1_lengths, sent2_lengths):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for each batch\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        ## init context and hidden weights for lstm cell\n",
    "        self.h_init,self.c_init = self.init_hidden(self.batch_size)\n",
    "        output1,_ = self.forward_once(sent1_batch,sent1_lengths)\n",
    "        self.h_init,self.c_init = self.init_hidden(self.batch_size)\n",
    "        output2,_ = self.forward_once(sent2_batch,sent2_lengths)\n",
    "        \n",
    "        ## Self attention Layer\n",
    "        attended_embeddings_sent1, attention_matrix_sent1 = self.SelfAtt.forward(output1)\n",
    "        attended_embeddings_sent2, attention_matrix_sent2 = self.SelfAtt.forward(output2)\n",
    "        \n",
    "        ## Fully connected layer \n",
    "        \n",
    "        final_embeddings_sent1= self.tanh(self.fc(attended_embeddings_sent1.reshape(output1.size(0),-1)))\n",
    "        final_embeddings_sent2= self.tanh(self.fc(attended_embeddings_sent2.reshape(output2.size(0),-1)))\n",
    "        \n",
    "        \n",
    "        #similarity score prediction\n",
    "        predictions = similarity_score(final_embeddings_sent1, final_embeddings_sent2)\n",
    "        \n",
    "        print(torch.cat((attention_matrix_sent1, attention_matrix_sent2), 1).size())\n",
    "        return predictions , \n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the attention block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        # TODO implement\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.ws1 = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.ws2 = nn.Linear(hidden_size, output_size, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "    ## the forward function would receive lstm's all hidden states as input\n",
    "    def forward(self, attention_input):\n",
    "        # TODO implement\n",
    "        #pass\n",
    "        \n",
    "        size = attention_input.size()\n",
    "        inp = attention_input.reshape(size[0]*size[1],size[2])\n",
    "        attention_matrix = self.softmax(self.ws2(self.tanh(self.ws1(inp))))\n",
    "        attention_matrix= attention_matrix.reshape(size[0], self.output_size, -1)\n",
    "        attended_embeddings_sent1= torch.bmm(attention_matrix , attention_input)\n",
    "        \n",
    "        return attended_embeddings_sent1, attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "output_size = 1\n",
    "hidden_size = 128\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 300\n",
    "embedding_weights = vocab.vectors\n",
    "lstm_layers = 4\n",
    "learning_rate = 1e-1\n",
    "fc_hidden_size = 64\n",
    "max_epochs = 5\n",
    "bidirectional = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## self attention config\n",
    "self_attention_config = {\n",
    "    \"hidden_size\": 150,  ## refers to variable 'da' in the ICLR paper\n",
    "    \"output_size\": 20,  ## refers to variable 'r' in the ICLR paper\n",
    "    \"penalty\": 0.0,  ## refers to penalty coefficient term in the ICLR paper\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## init siamese lstm\n",
    "siamese_lstm_attention = SiameseBiLSTMAttention(\n",
    "    batch_size=batch_size,\n",
    "    output_size=output_size,\n",
    "    hidden_size=hidden_size,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    embedding_weights=embedding_weights,\n",
    "    lstm_layers=lstm_layers,\n",
    "    self_attention_config=self_attention_config,\n",
    "    fc_hidden_size=fc_hidden_size,\n",
    "    device=device,\n",
    "    bidirectional=bidirectional,\n",
    ")\n",
    "## move model to device\n",
    "optimizer = torch.optim.Adam(params=siamese_lstm_attention.parameters())\n",
    "siamese_lstm_attention.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_lstm_attention.forward(batch[0],batch[1],7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\"\"\"\n",
    "Script for training the neural network and saving the better models \n",
    "while monitoring a metric like accuracy etc\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, dataloader, data, max_epochs, config_dict):\n",
    "    device = config_dict[\"device\"]\n",
    "    criterion = nn.MSELoss()\n",
    "    max_accuracy = 5e-1\n",
    "    train_loader , val_loader , test_loader = dataloader\n",
    "    dictionary_info={}\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        \n",
    "        try:\n",
    "            # Samples the batch\n",
    "            sent1_batch, sent2_batch, sent1_lengths, sent2_lengths,targets,raw_sent1,raw_sent2= next(iter(dataloader))\n",
    "\n",
    "        except StopIteration:\n",
    "            # restart the generator if the previous generator is exhausted.\n",
    "            train_generator = iter(train_loader)\n",
    "            sent1_batch, sent2_batch, sent1_lengths, sent2_lengths,targets,raw_sent1,raw_sent2= next(iter(dataloader))\n",
    "        \n",
    "        \n",
    "        predictions , attention_matrix = model.forward(sent1_batch, sent2_batch, sent1_lengths, sent2_lengths)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "             train_loss = criterion(predictions,targets) + attention_penalty_loss(attention_matrix, \n",
    "                                                                  config_dict['self_attention_config']['penalty'], device)\n",
    "                       \n",
    "        except RuntimeError:\n",
    "            \n",
    "            raise Exception(\"Model Loss gets nan values on regularization.Either remove regularization or add very small values\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # TODO: computing accuracy using sklearn's function\n",
    "        ## acc = \n",
    "        #accuracy = (torch.argmax(predictions, axis=-1) == targets).float().mean()\n",
    "        \n",
    "        acc=accuracy_score(targets, predictions)\n",
    "        \n",
    "        ## compute model metrics on dev set\n",
    "        val_acc, val_loss = evaluate_dev_set(\n",
    "            model, data, criterion, dataloader, config_dict, device\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        if val_acc > max_accuracy:\n",
    "            max_accuracy = val_acc\n",
    "            logging.info(\n",
    "                \"new model saved\")  \n",
    "            \n",
    "            ## save the model if it is better than the prior best\n",
    "            torch.save(model.state_dict(), \"{}.pth\".format(config_dict[\"model_name\"]))\n",
    "\n",
    "        logging.info(\n",
    "            \"Train loss: {} - acc: {} -- Validation loss: {} - acc: {}\".format(\n",
    "                torch.mean(train_loss.data.float()), acc, val_loss, val_acc\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "              print('[%d/%d] loss: %.3f, accuracy: %.3f' %\n",
    "                   (i , max_epochs - 1, loss.item(), acc.item()))\n",
    "        if epoch == max_epochs - 1:\n",
    "               print('Final accuracy: %.3f, expected %.3f' %\n",
    "                         (accuracy.item(), 1.0))\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_dev_set(model, data, criterion, data_loader, config_dict, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model performance on dev data\n",
    "    \"\"\"\n",
    "    logging.info(\"Evaluating accuracy on dev set\")\n",
    "\n",
    "    # TODO implement\n",
    "    pass\n",
    "\n",
    "def attention_penalty_loss(annotation_weight_matrix, penalty_coef, device):\n",
    "    \"\"\"\n",
    "    This function computes the loss from annotation/attention matrix\n",
    "    to reduce redundancy in annotation matrix and for attention\n",
    "    to focus on different parts of the sequence corresponding to the\n",
    "    penalty term 'P' in the ICLR paper\n",
    "    ----------------------------------\n",
    "    'annotation_weight_matrix' refers to matrix 'A' in the ICLR paper\n",
    "    annotation_weight_matrix shape: (batch_size, attention_out, seq_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, attention_out_size = annotation_weight_matrix.size(0), annotation_weight_matrix.size(1)\n",
    "    annotation_weight_matrix_trans = torch.transpose(annotation_weight_matrix, 0, 1)\n",
    "    identity = torch.eye(annotation_weight_matrix.size(0))\n",
    "    annotation_mul_difference=annotation_weight_matrix@annotation_weight_matrix_trans - identity\n",
    "    penalty = frobenius_norm(annotation_mul_difference)\n",
    "    return penalty_coef*penalty\n",
    "\n",
    "\n",
    "def frobenius_norm(annotation_mul_difference):\n",
    "    \"\"\"\n",
    "    Computes the frobenius norm of the annotation_mul_difference input as matrix\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    Args:\n",
    "      annotation_mul_difference= ||AAT - I||\n",
    " \n",
    "    Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "    \n",
    "#    torch.norm(annotation_mul_difference.float(), p='fro')\n",
    "#     torch.sum(torch.sum(torch.sum(annotation_mul_difference**2,1),1)**0.5).type(torch.DoubleTensor)\n",
    "    return torch.sqrt(torch.sum(annotation_mul_difference**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ce048",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_lstm_attention = train_model(\n",
    "    model=siamese_lstm_attention,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=train_loader,\n",
    "    data=sick_data,\n",
    "    max_epochs=max_epochs,\n",
    "    config_dict={\n",
    "        \"device\": device,\n",
    "        \"model_name\": \"siamese_lstm_attention\",\n",
    "        \"self_attention_config\": self_attention_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=  STSDataset(train_data_df['sent1_tensor'],\n",
    "                         train_data_df['sent2_tensor'],\n",
    "                         train_data_df['relatedness_score'],\n",
    "                         train_data_df['sents1_length_tensor'],\n",
    "                         train_data_df['sents2_length_tensor'],\n",
    "                         train_data_df['sentence_A'],\n",
    "                         train_data_df['sentence_B']\n",
    "                         )\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "# train_loader , val_loader , test_loader = sick_dataloaders\n",
    "train_generator = iter(train_loader)\n",
    "for i in range(100):\n",
    "    try:\n",
    "        # Samples the batch\n",
    "        sent1_batch, sent2_batch, sent1_lengths, sent2_lengths, targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "        print(Variable(targets))\n",
    "        break\n",
    "    except StopIteration:\n",
    "        # restart the generator if the previous generator is exhausted.\n",
    "        train_generator = iter(train_loader)\n",
    "        sent1_batch, sent2_batch, sent1_lengths, sent2_lengths, targets,raw_sent1,raw_sent2= next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b67d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.vectors[input]\n",
    "embedding = nn.Embedding(len(vocab), 300)\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6415540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "a=torch.randn([64, 40, 14])\n",
    "at= np.transpose(a, (0, 2, 1)).clone().detach().requires_grad_(True)\n",
    "# frobenius_norm(a)\n",
    "diff=a@at-torch.eye(a.size(1))\n",
    "diff.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "att=torch.randn([64, 40, 14])\n",
    "attT = att.transpose(1,2)\n",
    "identity = torch.eye(att.size(1))\n",
    "identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,att.size(1),att.size(1)))\n",
    "diff=att@attT - identity\n",
    "diff.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87963ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.tensor([0.3724, 0.4367, 0.3584, 0.4131, 0.4151, 0.3754, 0.4444, 0.3806, 0.4540,\n",
    "        0.3293, 0.4363, 0.3715, 0.4190, 0.4442, 0.4099, 0.4260, 0.3768, 0.4290,\n",
    "        0.4401, 0.4283, 0.3629, 0.3899, 0.3863, 0.4223, 0.4615, 0.4136, 0.3793,\n",
    "        0.4060, 0.4051, 0.4540, 0.4548, 0.4677, 0.4346, 0.3802, 0.3646, 0.4234,\n",
    "        0.4135, 0.3769, 0.4404, 0.3910, 0.4340, 0.4046, 0.3871, 0.3655, 0.4430,\n",
    "        0.4434, 0.3824, 0.4189, 0.4324, 0.3946, 0.3496, 0.4714, 0.4147, 0.4114,\n",
    "        0.4263, 0.4088, 0.3955, 0.3722, 0.4222, 0.3962, 0.3961, 0.4276, 0.3328,\n",
    "        0.3668]) \n",
    "t2=torch.tensor([0.7000, 0.1750, 0.5750, 0.8250, 0.3250, 0.4750, 0.8500, 0.7750, 0.5750,\n",
    "        0.6000, 0.5750, 0.4500, 0.6500, 0.6750, 0.7750, 0.9250, 0.1000, 0.8750,\n",
    "        0.5250, 0.6500, 0.5750, 0.3000, 0.0000, 0.6750, 0.0250, 0.7750, 0.9500,\n",
    "        0.6250, 0.3250, 0.9500, 0.6250, 0.5750, 0.7250, 0.4000, 0.9000, 0.7250,\n",
    "        0.9750, 0.0000, 0.5500, 0.6000, 0.8250, 0.2500, 0.7000, 0.9750, 0.8750,\n",
    "        0.5750, 0.6750, 0.6500, 0.0750, 0.9000, 0.1500, 0.8750, 0.7250, 0.6500,\n",
    "        0.8250, 0.5750, 0.5000, 0.7750, 0.5250, 0.0250, 0.9000, 0.5750, 0.7500,\n",
    "        0.0500])\n",
    "# tensor(0.1044, dtype=torch.float64, grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(list(t1.numpy()),list(t2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a515f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.metrics import pairwise.cosine_similarity,DistanceMetric , r2_score , max_error, mean_absolute_error, explained_variance_score\n",
    "r2_score(list(t2),list(t1))\n",
    "# DistanceMetric(list(t2),list(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_score(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(t1,t2)\n",
    "-1.7976931348623157e+308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(t1, t2, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.batch_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "70*64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5262269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0, 50, 10)\n",
    "y = x ** 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,4), dpi=100)\n",
    "\n",
    "# plot subplot 1\n",
    "axes[0].plot(x, x**2, color=\"green\", label=\"y = x**2\")\n",
    "axes[0].plot(x, x**3, color=\"red\", label=\"y = x**3\")\n",
    "axes[0].legend(loc=2); # upper left corner\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_title('Plot of y=x^2 and y=x^3')\n",
    "fig.savefig(\"plots.pdf\")\n",
    "# plot subplot 2\n",
    "axes[1].plot(x, x**2, color=\"violet\", label=\"y = x**2\")\n",
    "axes[1].plot(x, x**3, color=\"blue\", label=\"y = x**3\")\n",
    "axes[1].legend(loc=2); # upper left corner\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('y')\n",
    "axes[1].set_title('Plot of y=x^2 and y=x^3')\n",
    "\n",
    "# `fig.tight_layout()` automatically adjusts the positions of the axes on the figure canvas so that there is no overlapping content\n",
    "# comment this out to see the difference\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f93c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7fe0e7a57290>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe0e7a57650>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7fe0e7a57a90>,\n",
       "  <matplotlib.lines.Line2D at 0x7fe0e7a57ed0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7fe0e7a4ff90>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7fe0e7a63390>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7fe0e7a637d0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d7bde1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_train_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9532/116516476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_train_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;31m# Samples the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0msent1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent1_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_sent1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_sent2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_train_num' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in range(batch_train_num):\n",
    "            \n",
    "            try:\n",
    "                # Samples the batch\n",
    "                sent1_batch, sent2_batch, sent1_lengths, sent2_lengths,targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "\n",
    "            except StopIteration:\n",
    "                # restart the generator if the previous generator is exhausted.\n",
    "                train_generator = iter(train_loader)\n",
    "                sent1_batch, sent2_batch, sent1_lengths, sent2_lengths,targets,raw_sent1,raw_sent2= next(train_generator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c92d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function datasets.load.load_dataset(path: str, name: Union[str, NoneType] = None, data_dir: Union[str, NoneType] = None, data_files: Union[Dict, List] = None, split: Union[str, datasets.splits.Split, NoneType] = None, cache_dir: Union[str, NoneType] = None, features: Union[datasets.features.Features, NoneType] = None, download_config: Union[datasets.utils.file_utils.DownloadConfig, NoneType] = None, download_mode: Union[datasets.utils.download_manager.GenerateMode, NoneType] = None, ignore_verifications: bool = False, keep_in_memory: Union[bool, NoneType] = None, save_infos: bool = False, script_version: Union[str, datasets.utils.version.Version, NoneType] = None, use_auth_token: Union[str, bool, NoneType] = None, task: Union[str, datasets.tasks.base.TaskTemplate, NoneType] = None, streaming: bool = False, **config_kwargs) -> Union[datasets.dataset_dict.DatasetDict, datasets.arrow_dataset.Dataset, datasets.dataset_dict.IterableDatasetDict, datasets.iterable_dataset.IterableDataset]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e1eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now =17:53:36.033541\n",
      "type(now) = <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().time() # time object\n",
    "\n",
    "print(\"now =\"+ str(now))\n",
    "print(\"type(now) =\", type(str(now)))\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20247a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
